import{_ as t,c as o,o as e,a2 as r}from"./chunks/framework.503y2rod.js";const k=JSON.parse('{"title":"你可能感到疑惑的地方","description":"","frontmatter":{},"headers":[],"relativePath":"HoronGPT/FAQ.md","filePath":"HoronGPT/FAQ.md"}'),n={name:"HoronGPT/FAQ.md"},a=r('<h1 id="你可能感到疑惑的地方" tabindex="-1">你可能感到疑惑的地方 <a class="header-anchor" href="#你可能感到疑惑的地方" aria-label="Permalink to &quot;你可能感到疑惑的地方&quot;">​</a></h1><h2 id="_1000-tokens-是什么概念-粗略估算" tabindex="-1"><strong>1000 Tokens 是什么概念？（粗略估算）</strong> <a class="header-anchor" href="#_1000-tokens-是什么概念-粗略估算" aria-label="Permalink to &quot;**1000 Tokens 是什么概念？（粗略估算）**&quot;">​</a></h2><p>需要注意的是，这个数字仅仅是一个估算，具体的数字还可能会因为不同的上下文和语言模型而有所不同。</p><p>对于英文，官方也给出简洁的估算方式 <a href="https://n3xtchen.github.io/NDigitalGarden/notes/2023-03-10-gpt3-token/#fn:1" target="_blank" rel="noreferrer">1</a>:</p><p>1 token ~= 4 chars in English</p><p>1 token ~= ¾ words</p><p>100 tokens ~= 75 words 或者</p><p>1-2 sentence ~= 30 tokens</p><p>1 paragraph ~= 100 tokens</p><p>1,500 words ~= 2048 tokens</p><p>简单总结，就是 <strong>1000 Token 约等于750个英文单词</strong>，67个句子，10个段落。</p><h3 id="对于中文-如何计算-token-量" tabindex="-1"><strong>对于中文，如何计算 Token 量？</strong> <a class="header-anchor" href="#对于中文-如何计算-token-量" aria-label="Permalink to &quot;**对于中文，如何计算 Token 量？**&quot;">​</a></h3><p>在 <strong>ChatGPT</strong> 中，每个 <strong>Token</strong> 的长度并不是固定的，它们的长度是根据上下文和语言模型计算得出的。但是，对于一个通常长度的 <strong>Token</strong>，我们可以估算出大约需要多少个中文字符来达到相同的长度。</p><p>从官方文档可知，1000 Token 约等于 750 个英文单词，相当于 4000 个英文字符。根据一些研究的结果，英文单词的平均长度为 4 个字符，而中文单词的平均长度为 2 个汉字，那么<strong>1000个token大约相当于2000个中文汉字</strong>，200个句子（一般来说，一句话通常包含10个左右的汉字），另外一段话通常包含几个句子，其长度也会因文本类型、结构和主题而有所不同。</p><h2 id="各个模型之间有什么区别" tabindex="-1"><strong>各个模型之间有什么区别？</strong> <a class="header-anchor" href="#各个模型之间有什么区别" aria-label="Permalink to &quot;**各个模型之间有什么区别？**&quot;">​</a></h2><table><thead><tr><th><strong>模型类型</strong></th><th><strong>每1000个Tokens的费用($)</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>gpt-4.0</td><td>0.06</td><td>比 GPT-3.5 模型更强大，能够执行更复杂的任务，并针对聊天场景进行了优化。 会不断迭代更新</td></tr><tr><td>gpt-3.5-turbo</td><td>0.002</td><td>目前主流的模型，便宜快速，推荐</td></tr><tr><td>Ada</td><td>0.0004</td><td>更适用于文本分类、命名实体识别和语义理解等任务</td></tr><tr><td>Davinci</td><td>0.020.0005</td><td>最强（上一代）的 GPT3 的模型</td></tr></tbody></table>',16),s=[a];function d(h,p,i,c,g,l){return e(),o("div",null,s)}const T=t(n,[["render",d]]);export{k as __pageData,T as default};
